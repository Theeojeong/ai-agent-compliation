```
# ğŸ§  AI Agent Compilation â€” ì‹¤ì‚¬ìš© ì¤‘ì‹¬ ë©€í‹° ì—ì´ì „íŠ¸ ì»¬ë ‰ì…˜

ì´ ì €ì¥ì†ŒëŠ” ì‹¤ì œ ì—…ë¬´/í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤ì— ë°”ë¡œ íˆ¬ì… ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤ì„ ëª¨ì•„ë‘” ì»¬ë ‰ì…˜ì…ë‹ˆë‹¤.
ê° ì—ì´ì „íŠ¸ëŠ” ëª©ì ì— ë§ê²Œ ì„¤ê³„ë˜ì–´ ìˆìœ¼ë©°, ì„¤ì¹˜ë¶€í„° ì‹¤í–‰ê¹Œì§€ ì¦‰ì‹œ ë”°ë¼ í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

> í¬í•¨ëœ ì—ì´ì „íŠ¸: `content-pipline-agent`, `job-hunter-agent`, `news-reader-agent`

---

## ğŸš€ ê³µí†µ ì‚¬ì–‘
- **ëŸ°íƒ€ì„**: Python `>= 3.13`
- **í•µì‹¬ í”„ë ˆì„ì›Œí¬**: `crewai[tools]`
- **ê¶Œì¥ íŒ¨í‚¤ì§€ ê´€ë¦¬ì**: `uv` ë˜ëŠ” `pip`
- **í™˜ê²½ë³€ìˆ˜**: í•„ìš” ì‹œ `.env` íŒŒì¼ì— í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (í‚¤ ê°’ì€ ë³´ì•ˆìƒ ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤).
  - `OPENAI_API_KEY`, `SERPER_API_KEY`, `FIRECRAWL_API_KEY` ë“±

ì„¤ì¹˜/ì‹¤í–‰ ê¸°ë³¸ ì˜ˆì‹œ:

```

```bash
# uv ì‚¬ìš© ì‹œ (ê¶Œì¥)
cd <agent-folder>
uv sync
uv run python main.py  # ë˜ëŠ” main_reference.py

# pip ì‚¬ìš© ì‹œ
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -e .
python main.py  # ë˜ëŠ” main_reference.py
```

```

Playwrightë¥¼ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ì˜ ê²½ìš° ë¸Œë¼ìš°ì € ë°”ì´ë„ˆë¦¬ ì„¤ì¹˜ê°€ ì¶”ê°€ë¡œ í•„ìš”í•©ë‹ˆë‹¤:

```

```bash
uv run playwright install  # ë˜ëŠ”: python -m playwright install
```

```

---

## âœï¸ í”„ë¡œì íŠ¸ ì°¸ì—¬ì
- í”„ë¡œì íŠ¸ ì†Œìœ /ë©”ì¸í„°ë„ˆ: ì •ì¬í˜„

---

## ğŸ“¦ content-pipline-agent
- **í”„ë¡œì íŠ¸ëª…**: "content-pipline-agent"
- **ì„¤ëª…**: Firecrawl ê¸°ë°˜ì˜ ê³ ì‹ ë¢° ì›¹ ê²€ìƒ‰/ìŠ¤í¬ë˜í•‘ íˆ´ì„ íƒ‘ì¬í•œ ì½˜í…ì¸  ë¦¬ì„œì¹˜ íŒŒì´í”„ë¼ì¸ì˜ í† ëŒ€ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ë§ˆí¬ë‹¤ìš´ì„ ì •ê·œì‹ìœ¼ë¡œ ì •ì œí•´ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬(ìš”ì•½/ë¶„ë¥˜/ì§‘ê³„)ì— ì í•©í•œ ì…ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì„¤ì¹˜ ë° ì‹¤í–‰
```

```bash
cd content-pipline-agent
uv sync  # ë˜ëŠ” pip install -e .
cp .env.example .env  # ì—†ë‹¤ë©´ .envë¥¼ ìƒì„±í•˜ê³  í•„ìš”í•œ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”
uv run python main.py
```

```

í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜: `OPENAI_API_KEY`, `FIRECRAWL_API_KEY`

### ì¤‘ìš”í•œ ì½”ë“œ
Firecrawl ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ ì •ì œí•´ ë°˜í™˜í•˜ëŠ” íˆ´:

```

```python
@tool
def web_search_tool(query: str):
    app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))
    response = app.search(query=query, limit=5, scrape_options=ScrapeOptions(formats=["markdown"]))
    if not response.success:
        return "Error using tool."

    cleaned_chunks = []
    for result in response.data:
        cleaned = re.sub(r"\\+|\n+", "", result["markdown"]).strip()
        cleaned = re.sub(r"\[[^\]]+\]\([^\)]+\)|https?://[^\s]+", "", cleaned)
        cleaned_chunks.append({
            "title": result["title"],
            "url": result["url"],
            "markdown": cleaned,
        })
    return cleaned_chunks
```

```

ì„¤ëª…:
```

```text
- Firecrawlì˜ ê²€ìƒ‰+ìŠ¤í¬ë© ê²°ê³¼ë¥¼ ë°›ì•„ ë¶ˆí•„ìš”í•œ ê°œí–‰/ë§í¬/URLì„ ì œê±°í•´ ëª¨ë¸ ì¹œí™”ì ì¸ í…ìŠ¤íŠ¸ë¡œ ì •ì œí•©ë‹ˆë‹¤.
- ë„êµ¬(@tool)ëŠ” CrewAI íƒœìŠ¤í¬ì—ì„œ ì¦‰ì‹œ í˜¸ì¶œ ê°€ëŠ¥í•˜ë„ë¡ ë˜í•‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
```

```

---

## ğŸ’¼ job-hunter-agent
- **í”„ë¡œì íŠ¸ëª…**: "job-hunter-agent"
- **ì„¤ëª…**: êµ¬ì¸ ê³µê³  ìˆ˜ì§‘ â†’ ë§¤ì¹­ ì ìˆ˜í™” â†’ í¬ì§€ì…˜ ì„ íƒ â†’ ì´ë ¥ì„œ ë¦¬ë¼ì´íŠ¸ â†’ ê¸°ì—… ë¶„ì„ â†’ ë©´ì ‘ ì¤€ë¹„ê¹Œì§€ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” í’€ íŒŒì´í”„ë¼ì¸í˜• ë©€í‹° ì—ì´ì „íŠ¸. `pydantic` ìŠ¤í‚¤ë§ˆë¥¼ í†µí•´ ì¶œë ¥ êµ¬ì¡°ë¥¼ ì—„ê²©íˆ ë³´ì¥í•©ë‹ˆë‹¤.

### ì„¤ì¹˜ ë° ì‹¤í–‰
```

```bash
cd job-hunter-agent
uv sync  # ë˜ëŠ” pip install -e .
cp .env.example .env  # ì—†ë‹¤ë©´ .env ìƒì„± í›„ í‚¤ ì„¤ì •
uv run python main_reference.py  # ë°ëª¨ íŒŒì´í”„ë¼ì¸ ì§„ì…ì 
```

```

í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜(ì˜ˆ): `OPENAI_API_KEY`, `FIRECRAWL_API_KEY`

### íŒŒì´í”„ë¼ì¸ ê°œìš”
```

```text
1) job_search_agent: Firecrawl ê¸°ë°˜ ì›¹ ê²€ìƒ‰ ë„êµ¬ë¡œ ê³µê³  ìˆ˜ì§‘
2) job_matching_agent: í›„ë³´ì í”„ë¡œí•„ê³¼ ê³µê³ ì˜ ì •í•©ì„±ì„ ì ìˆ˜í™”(1~5) ë° ì‚¬ìœ  ê¸°ë¡
3) job_selection_task: ìµœì  ê³µê³  1ê±´ ì„ íƒ
4) resume_optimization_agent: ê³µê³  ì •í•©í˜• ì´ë ¥ì„œ ë¦¬ë¼ì´íŠ¸
5) company_research_agent: íšŒì‚¬ ì‹ í˜¸/í•µì‹¬ ì£¼ì œ ë¶„ì„
6) interview_prep_agent: ë©´ì ‘ ì§ˆë¬¸, ì–´í•„ í¬ì¸íŠ¸ ë¸Œë¦¬í•‘ êµ¬ì„±
```

```

### ì¤‘ìš”í•œ ì½”ë“œ
ê°•íƒ€ì… ì¶œë ¥ìœ¼ë¡œ ì•ˆì •ì„±ì„ í™•ë³´í•˜ëŠ” ëª¨ë¸ ì •ì˜:

```

```python
class Job(BaseModel):
    job_title: str
    company_name: str
    job_location: str
    job_posting_url: str
    job_summary: str
    # ...ì„ íƒ í•„ë“œë“¤(benefits, skills ë“±)

class JobList(BaseModel):
    jobs: List[Job]

class RankedJob(BaseModel):
    job: Job
    match_score: int  # 1~5
    reason: str

class RankedJobList(BaseModel):
    ranked_jobs: List[RankedJob]

class ChosenJob(BaseModel):
    job: Job
    selected: bool
    reason: str
```

```

ì„¤ëª…:
```

```text
- ê° íƒœìŠ¤í¬ì˜ ì¶œë ¥ì€ ìƒí˜¸ í•©ì˜ëœ pydantic ìŠ¤í‚¤ë§ˆë¡œ ì—„ê²©íˆ ê²€ì¦ë˜ì–´, ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë‹¨ê³„ì—ì„œ íŒŒì‹±/ê²€ì¦ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
- ë§¤ì¹­ ë‹¨ê³„ì—ì„œ ì›ë³¸ í•„ë“œë¥¼ ë³´ì¡´í•˜ê³  `match_score`, `reason`ë§Œ ì¶”ê°€í•˜ì—¬ íˆ¬ëª…ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
```

```

---

## ğŸ“° news-reader-agent
- **í”„ë¡œì íŠ¸ëª…**: "news-reader-agent"
- **ì„¤ëª…**: íŠ¸ë Œë”©/ì£¼ì œ ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ â†’ ë‹¤ë‹¨ê³„ ìš”ì•½(Headline/Executive/Comprehensive) â†’ ì—ë””í† ë¦¬ì–¼ íë ˆì´ì…˜ê¹Œì§€ ìë™í™”. ê²€ìƒ‰ì—”ì§„(Serper) + Playwright ìŠ¤í¬ë ˆì´í¼ë¡œ ì‹ ë¢°ë„ì™€ ì»¤ë²„ë¦¬ì§€ë¥¼ ë™ì‹œì— í™•ë³´í•©ë‹ˆë‹¤.

### ì„¤ì¹˜ ë° ì‹¤í–‰
```

```bash
cd news-reader-agent
uv sync  # ë˜ëŠ” pip install -e .
uv run playwright install  # ìŠ¤í¬ë©ìš© ë¸Œë¼ìš°ì € ì„¤ì¹˜
cp .env.example .env  # ì—†ë‹¤ë©´ .env ìƒì„± í›„ í‚¤ ì„¤ì •
uv run python main.py  # topic íŒŒë¼ë¯¸í„°ëŠ” main.pyì—ì„œ ì„¤ì • ê°€ëŠ¥
```

```

í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜(ì˜ˆ): `OPENAI_API_KEY`, `SERPER_API_KEY`

### ì¤‘ìš”í•œ ì½”ë“œ
Serper ê²€ìƒ‰ + Playwright ìŠ¤í¬ë ˆì´í¼ ì¡°í•©:

```

```python
search_tool = SerperDevTool(n_results=30)

@tool
def scrape_tool(url: str):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(url)
        time.sleep(5)
        html = page.content()
        browser.close()
        soup = BeautifulSoup(html, 'html.parser')
        for tag in soup.find_all(["header","footer","nav","aside","script","style","noscript","iframe",
                                   "form","button","input","select","textarea","img","svg","canvas","audio",
                                   "video","embed","object"]):
            tag.decompose()
        content = soup.get_text(separator=" ")
        return content if content else "No content"
```

```

ì„¤ëª…:
```

```text
- ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë³¸ë¬¸ì´ ìˆëŠ” ì•„í‹°í´ í˜ì´ì§€ë§Œ ì„ ë³„í•˜ê³ , ë¶ˆí•„ìš”í•œ DOM ìš”ì†Œë¥¼ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ì´í›„ íƒœìŠ¤í¬ì—ì„œ Headline/Executive/Comprehensive 3ë‹¨ê³„ ìš”ì•½ê³¼ ìµœì¢… ë¦¬í¬íŠ¸ í¸ì§‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
```

```

---

## ğŸ™Œ ê¸°ì—¬ ë°©ë²•
```

```bash
# ì´ ì €ì¥ì†Œë¥¼ í¬í¬/í´ë¡  í›„ ë¸Œëœì¹˜ì—ì„œ ì‘ì—…í•´ì£¼ì„¸ìš”
git checkout -b feat/<feature-name>
git commit -m "feat: <ì„¤ëª…>"
git push origin feat/<feature-name>
```

```

ì´ìŠˆ/PR í™˜ì˜í•©ë‹ˆë‹¤.
```
