# ğŸ§  AI Agent Compilation â€” ì‹¤ì‚¬ìš© ì¤‘ì‹¬ ë©€í‹° ì—ì´ì „íŠ¸ ì»¬ë ‰ì…˜

ì‹¤ì œ ì—…ë¬´/í•™ìŠµ í™˜ê²½ì—ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ë“¤ì„ ëª¨ì•˜ìŠµë‹ˆë‹¤. ëª©ì ë³„ë¡œ ìµœì í™”ë˜ì–´ ìˆìœ¼ë©°, ì„¤ì¹˜ì™€ ì‹¤í–‰ì´ ê°„ë‹¨í•©ë‹ˆë‹¤.

í¬í•¨ëœ ì—ì´ì „íŠ¸: `content-pipline-agent`, `job-hunter-agent`, `news-reader-agent`

---

## ğŸš€ ê³µí†µ ì‚¬ì–‘

- ëŸ°íƒ€ì„: Python >= 3.13
- í”„ë ˆì„ì›Œí¬: crewai[tools]
- íŒ¨í‚¤ì§€ ê´€ë¦¬ì: uv ë˜ëŠ” pip
- í™˜ê²½ ë³€ìˆ˜: `.env`ì— ë‹¤ìŒ ê°’ì„ ì„¤ì •í•˜ì„¸ìš”

(.env):

```bash
OPENAI_API_KEY=sk-...
SERPER_API_KEY=serper_...
FIRECRAWL_API_KEY=fc_...
```

ì„¤ì¹˜/ì‹¤í–‰ ê³µí†µ ì˜ˆì‹œ:

```bash
# uv (ê¶Œì¥)
cd <agent-folder>
uv sync
uv run python main.py  # ë˜ëŠ” main_reference.py

# pip
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -e .
python main.py  # ë˜ëŠ” main_reference.py
```

Playwright ì‚¬ìš© ì—ì´ì „íŠ¸ëŠ” ë¸Œë¼ìš°ì € ë°”ì´ë„ˆë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤:

```bash
uv run playwright install  # ë˜ëŠ”: python -m playwright install
```

---

## âœï¸ í”„ë¡œì íŠ¸ ì°¸ì—¬ì

- í”„ë¡œì íŠ¸ ì†Œìœ /ë©”ì¸í„°ë„ˆ: ì •ì¬í˜„

---

## ğŸ“¦ content-pipline-agent

- í”„ë¡œì íŠ¸ëª…: "content-pipline-agent"
- ì„¤ëª…: Firecrawl ê¸°ë°˜ì˜ ì‹ ë¢°ë„ ë†’ì€ ì›¹ ê²€ìƒ‰/ìŠ¤í¬ë© íˆ´ì„ ê°–ì¶˜ ì½˜í…ì¸  ë¦¬ì„œì¹˜ íŒŒì´í”„ë¼ì¸. ë§ˆí¬ë‹¤ìš´ì„ ì •ì œí•´ ìš”ì•½/ë¶„ë¥˜ ë“± í›„ì† íƒœìŠ¤í¬ì— ì í•©í•œ ì…ë ¥ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

### ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
cd content-pipline-agent
uv sync  # ë˜ëŠ” pip install -e .
touch .env  # í™˜ê²½ ë³€ìˆ˜ ì‘ì„±
uv run python main.py
```

í•„ìš” ë³€ìˆ˜: `OPENAI_API_KEY`, `FIRECRAWL_API_KEY`

### ì¤‘ìš”í•œ ì½”ë“œ

Firecrawl ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •ì œí•˜ëŠ” ë„êµ¬:

```python
@tool
def web_search_tool(query: str):
    app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))
    response = app.search(query=query, limit=5, scrape_options=ScrapeOptions(formats=["markdown"]))
    if not response.success:
        return "Error using tool."

    cleaned_chunks = []
    for result in response.data:
        cleaned = re.sub(r"\\+|\n+", "", result["markdown"]).strip()
        cleaned = re.sub(r"\[[^\]]+\]\([^\)]+\)|https?://[^\s]+", "", cleaned)
        cleaned_chunks.append({
            "title": result["title"],
            "url": result["url"],
            "markdown": cleaned,
        })
    return cleaned_chunks
```

ìš”ì 

- ê²€ìƒ‰+ìŠ¤í¬ë© ê²°ê³¼ì—ì„œ ê°œí–‰/ë§í¬/URLì„ ì œê±°í•´ ëª¨ë¸ ì¹œí™” í…ìŠ¤íŠ¸ë¡œ ì •ì œí•©ë‹ˆë‹¤.
- CrewAI íƒœìŠ¤í¬ì—ì„œ ê³§ë°”ë¡œ í˜¸ì¶œ ê°€ëŠ¥í•œ `@tool` í˜•íƒœë¡œ ì œê³µë©ë‹ˆë‹¤.

---

## ğŸ’¼ job-hunter-agent

- í”„ë¡œì íŠ¸ëª…: "job-hunter-agent"
- ì„¤ëª…: ê³µê³  ìˆ˜ì§‘ â†’ ë§¤ì¹­ ì ìˆ˜í™” â†’ í¬ì§€ì…˜ ì„ íƒ â†’ ì´ë ¥ì„œ ë¦¬ë¼ì´íŠ¸ â†’ ê¸°ì—… ë¶„ì„ â†’ ë©´ì ‘ ì¤€ë¹„ê¹Œì§€ ì´ì–´ì§€ëŠ” í’€ íŒŒì´í”„ë¼ì¸ ë©€í‹° ì—ì´ì „íŠ¸. `pydantic` ìŠ¤í‚¤ë§ˆë¡œ ì¶œë ¥ êµ¬ì¡°ë¥¼ ì—„ê²©íˆ ë³´ì¥í•©ë‹ˆë‹¤.

### ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
cd job-hunter-agent
uv sync  # ë˜ëŠ” pip install -e .
touch .env  # í™˜ê²½ ë³€ìˆ˜ ì‘ì„±
uv run python main_reference.py
```

í•„ìš” ë³€ìˆ˜: `OPENAI_API_KEY`, `FIRECRAWL_API_KEY`

### íŒŒì´í”„ë¼ì¸ ê°œìš”

1. job_search_agent: Firecrawl ë„êµ¬ë¡œ ê³µê³  ìˆ˜ì§‘
2. job_matching_agent: ì •í•©ì„± ì ìˆ˜(1~5)ì™€ ì‚¬ìœ  ë¶€ì—¬
3. job_selection_task: ìµœì  ê³µê³  ì„ íƒ
4. resume_optimization_agent: ê³µê³  ë§ì¶¤ ì´ë ¥ì„œ ë¦¬ë¼ì´íŠ¸
5. company_research_agent: íšŒì‚¬ ì‹ í˜¸/í•µì‹¬ ì£¼ì œ ë¶„ì„
6. interview_prep_agent: ì§ˆë¬¸/ì–´í•„ í¬ì¸íŠ¸ ë¸Œë¦¬í•‘

### ì¤‘ìš”í•œ ì½”ë“œ

ê°•íƒ€ì… ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:

```python
class Job(BaseModel):
    job_title: str
    company_name: str
    job_location: str
    job_posting_url: str
    job_summary: str

class JobList(BaseModel):
    jobs: List[Job]

class RankedJob(BaseModel):
    job: Job
    match_score: int
    reason: str

class RankedJobList(BaseModel):
    ranked_jobs: List[RankedJob]

class ChosenJob(BaseModel):
    job: Job
    selected: bool
    reason: str
```

ìš”ì 

- ê° ë‹¨ê³„ ì¶œë ¥ì´ ìŠ¤í‚¤ë§ˆë¡œ ê²€ì¦ë˜ì–´ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜ë¥¼ ì¤„ì…ë‹ˆë‹¤.
- ì›ë³¸ í•„ë“œë¥¼ ë³´ì¡´í•˜ê³  `match_score`, `reason`ë§Œ ì¶”ê°€í•´ íˆ¬ëª…ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.

---

## ğŸ“° news-reader-agent

- í”„ë¡œì íŠ¸ëª…: "news-reader-agent"
- ì„¤ëª…: ì£¼ì œ ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ â†’ 3ë‹¨ê³„ ìš”ì•½(Headline/Executive/Comprehensive) â†’ ì—ë””í† ë¦¬ì–¼ íë ˆì´ì…˜ ìë™í™”. Serper ê²€ìƒ‰ + Playwright ìŠ¤í¬ë©ìœ¼ë¡œ í­ë„“ê³  ì‹ ë¢°ë„ ë†’ì€ ìˆ˜ì§‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
cd news-reader-agent
uv sync  # ë˜ëŠ” pip install -e .
uv run playwright install
touch .env  # í™˜ê²½ ë³€ìˆ˜ ì‘ì„±
uv run python main.py
```

í•„ìš” ë³€ìˆ˜: `OPENAI_API_KEY`, `SERPER_API_KEY`

### ì¤‘ìš”í•œ ì½”ë“œ

ê°„ê²°í•œ ìŠ¤í¬ë ˆì´í¼:

```python
search_tool = SerperDevTool(n_results=30)

@tool
def scrape_tool(url: str):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(url)
        time.sleep(5)
        html = page.content()
        browser.close()
        soup = BeautifulSoup(html, 'html.parser')
        for tag in soup.find_all(["header","footer","nav","aside","script","style","noscript","iframe",
                                   "form","button","input","select","textarea","img","svg","canvas","audio",
                                   "video","embed","object"]):
            tag.decompose()
        content = soup.get_text(separator=" ")
        return content or "No content"
```

ìš”ì 

- ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¸°ë„ë¡ ë¶ˆí•„ìš”í•œ DOM ìš”ì†Œë¥¼ ì œê±°í•©ë‹ˆë‹¤.
- í›„ì† íƒœìŠ¤í¬ì—ì„œ ë‹¤ë‹¨ê³„ ìš”ì•½ê³¼ ìµœì¢… ë¦¬í¬íŠ¸ í¸ì§‘ì„ ì§„í–‰í•©ë‹ˆë‹¤.

---

## ğŸ™Œ ê¸°ì—¬ ë°©ë²•

```bash
git checkout -b feat/<feature-name>
git commit -m "feat: <ì„¤ëª…>"
git push origin feat/<feature-name>
```

ì´ìŠˆ/PR í™˜ì˜í•©ë‹ˆë‹¤!
